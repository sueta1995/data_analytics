{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c70ce87",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1. Прогнозирование моделью линейной регрессии\n",
    "\n",
    "### 0. Загрузка данных\n",
    "\n",
    "Перед нормированием и расчетом весов необходимо загрузить данные с помощью библиотеки numpy (```X``` - матрица признаков, ```y``` - матрица целевых значений)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "66b95a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрицы X и y:\n",
      "[[7.000e+00 1.590e+01 8.200e+00 5.100e+00 1.380e+01 2.290e+02 1.720e+02\n",
      "  2.000e+01 2.104e+03]\n",
      " [7.200e+00 1.820e+01 7.400e+00 6.100e+00 1.430e+01 1.460e+02 1.670e+02\n",
      "  2.910e+01 2.489e+03]\n",
      " [7.900e+00 1.970e+01 6.400e+00 4.700e+00 1.980e+01 1.740e+02 1.440e+02\n",
      "  2.280e+01 2.428e+03]\n",
      " [7.700e+00 2.080e+01 6.900e+00 5.200e+00 1.710e+01 1.280e+02 1.110e+02\n",
      "  4.270e+01 2.494e+03]\n",
      " [9.200e+00 1.590e+01 7.800e+00 5.300e+00 1.670e+01 1.690e+02 1.480e+02\n",
      "  2.270e+01 2.094e+03]\n",
      " [7.600e+00 1.640e+01 6.700e+00 4.700e+00 1.550e+01 1.440e+02 1.500e+02\n",
      "  2.790e+01 1.768e+03]\n",
      " [7.300e+00 1.830e+01 6.300e+00 4.900e+00 1.960e+01 1.380e+02 1.330e+02\n",
      "  3.370e+01 1.982e+03]\n",
      " [7.900e+00 1.640e+01 6.800e+00 5.000e+00 1.760e+01 1.970e+02 1.550e+02\n",
      "  2.660e+01 1.621e+03]\n",
      " [7.900e+00 1.700e+01 6.300e+00 4.400e+00 2.010e+01 1.820e+02 1.590e+02\n",
      "  3.050e+01 1.631e+03]\n",
      " [8.000e+00 1.690e+01 8.200e+00 4.600e+00 1.550e+01 5.200e+02 1.970e+02\n",
      "  1.910e+01 1.066e+03]\n",
      " [7.200e+00 1.760e+01 8.100e+00 5.200e+00 1.610e+01 1.430e+02 1.650e+02\n",
      "  3.120e+01 1.183e+03]\n",
      " [8.700e+00 1.600e+01 7.600e+00 4.400e+00 1.890e+01 2.140e+02 1.610e+02\n",
      "  2.270e+01 1.308e+03]\n",
      " [7.800e+00 1.790e+01 7.200e+00 4.300e+00 1.570e+01 1.580e+02 1.630e+02\n",
      "  2.440e+01 1.475e+03]\n",
      " [8.000e+00 1.690e+01 6.900e+00 4.700e+00 1.680e+01 1.850e+02 1.460e+02\n",
      "  1.980e+01 2.081e+03]\n",
      " [7.500e+00 1.940e+01 6.700e+00 4.600e+00 1.930e+01 1.530e+02 1.650e+02\n",
      "  2.860e+01 2.109e+03]\n",
      " [7.300e+00 1.940e+01 7.400e+00 5.000e+00 2.010e+01 2.000e+02 1.750e+02\n",
      "  1.620e+01 1.757e+03]\n",
      " [7.600e+00 1.730e+01 7.100e+00 5.300e+00 1.200e+01 1.800e+02 1.540e+02\n",
      "  2.130e+01 2.111e+03]\n",
      " [9.600e+00 1.300e+01 6.400e+00 3.500e+00 1.680e+01 1.200e+02 1.170e+02\n",
      "  4.320e+01 2.112e+03]\n",
      " [9.000e+00 1.410e+01 7.000e+00 3.300e+00 1.520e+01 1.320e+02 1.260e+02\n",
      "  3.470e+01 1.794e+03]\n",
      " [1.020e+01 1.300e+01 7.100e+00 3.200e+00 1.610e+01 1.450e+02 1.210e+02\n",
      "  2.730e+01 1.688e+03]\n",
      " [8.100e+00 1.630e+01 6.200e+00 3.900e+00 1.710e+01 1.370e+02 1.210e+02\n",
      "  3.200e+01 1.774e+03]\n",
      " [8.000e+00 1.750e+01 6.700e+00 4.000e+00 1.640e+01 1.810e+02 1.820e+02\n",
      "  2.200e+01 1.773e+03]\n",
      " [1.070e+01 1.440e+01 8.000e+00 4.000e+00 1.870e+01 1.290e+02 1.300e+02\n",
      "  4.630e+01 1.344e+03]\n",
      " [2.180e+01 7.500e+00 6.900e+00 1.300e+00 1.760e+01 8.600e+01 7.900e+01\n",
      "  4.150e+01 6.730e+02]\n",
      " [1.370e+01 1.040e+01 7.100e+00 3.400e+00 1.450e+01 1.280e+02 1.020e+02\n",
      "  4.250e+01 8.590e+02]\n",
      " [1.290e+01 1.030e+01 7.000e+00 3.300e+00 1.630e+01 1.230e+02 1.070e+02\n",
      "  4.570e+01 9.250e+02]\n",
      " [1.330e+01 1.300e+01 6.600e+00 2.600e+00 1.780e+01 1.280e+02 1.010e+02\n",
      "  4.280e+01 9.680e+02]\n",
      " [1.000e+01 1.530e+01 8.800e+00 5.000e+00 1.920e+01 1.750e+02 1.600e+02\n",
      "  3.240e+01 1.565e+03]\n",
      " [1.070e+01 1.350e+01 8.100e+00 4.500e+00 2.170e+01 1.510e+02 1.540e+02\n",
      "  3.960e+01 1.325e+03]\n",
      " [9.200e+00 1.580e+01 8.000e+00 4.800e+00 1.870e+01 1.460e+02 1.400e+02\n",
      "  3.340e+01 1.497e+03]\n",
      " [1.120e+01 1.270e+01 7.300e+00 3.700e+00 1.830e+01 1.580e+02 1.910e+02\n",
      "  3.240e+01 1.059e+03]\n",
      " [9.400e+00 1.370e+01 6.700e+00 3.400e+00 1.840e+01 1.580e+02 1.440e+02\n",
      "  2.610e+01 1.915e+03]\n",
      " [9.000e+00 1.460e+01 7.300e+00 4.300e+00 2.260e+01 1.130e+02 1.320e+02\n",
      "  5.040e+01 2.660e+03]\n",
      " [1.030e+01 1.350e+01 7.500e+00 4.000e+00 1.970e+01 1.150e+02 1.450e+02\n",
      "  4.930e+01 1.534e+03]\n",
      " [9.200e+00 1.580e+01 5.900e+00 3.800e+00 1.890e+01 1.840e+02 1.750e+02\n",
      "  2.570e+01 2.654e+03]\n",
      " [8.500e+00 1.560e+01 6.700e+00 4.700e+00 1.750e+01 1.630e+02 1.690e+02\n",
      "  2.950e+01 2.508e+03]\n",
      " [9.000e+00 1.480e+01 7.000e+00 4.700e+00 1.660e+01 1.710e+02 1.820e+02\n",
      "  2.790e+01 1.987e+03]\n",
      " [1.420e+01 1.310e+01 7.100e+00 3.800e+00 2.790e+01 1.880e+02 1.480e+02\n",
      "  2.620e+01 2.176e+03]\n",
      " [8.700e+00 1.470e+01 7.300e+00 4.400e+00 2.080e+01 1.580e+02 1.460e+02\n",
      "  3.370e+01 1.871e+03]\n",
      " [8.900e+00 1.660e+01 7.000e+00 4.900e+00 1.960e+01 2.540e+02 2.600e+02\n",
      "  1.610e+01 1.563e+03]\n",
      " [8.500e+00 1.410e+01 7.000e+00 4.500e+00 1.590e+01 1.360e+02 1.560e+02\n",
      "  3.980e+01 2.665e+03]\n",
      " [1.020e+01 1.230e+01 7.300e+00 4.600e+00 1.630e+01 1.570e+02 1.700e+02\n",
      "  2.970e+01 2.273e+03]\n",
      " [9.100e+00 1.300e+01 7.000e+00 5.300e+00 2.120e+01 1.730e+02 1.900e+02\n",
      "  3.060e+01 2.635e+03]\n",
      " [1.060e+01 9.800e+00 7.900e+00 5.700e+00 2.130e+01 2.900e+02 2.930e+02\n",
      "  1.920e+01 2.478e+03]\n",
      " [1.170e+01 1.200e+01 6.500e+00 3.500e+00 1.520e+01 1.220e+02 1.550e+02\n",
      "  5.520e+01 2.580e+03]\n",
      " [2.000e+01 1.300e+01 5.900e+00 1.900e+00 2.800e+01 8.400e+01 1.010e+02\n",
      "  7.320e+01 2.713e+03]\n",
      " [9.900e+00 1.400e+01 7.100e+00 4.400e+00 2.460e+01 1.610e+02 2.010e+02\n",
      "  2.530e+01 2.222e+03]\n",
      " [9.800e+00 1.400e+01 7.200e+00 4.800e+00 1.980e+01 2.460e+02 2.960e+02\n",
      "  2.420e+01 2.417e+03]\n",
      " [1.060e+01 1.460e+01 6.300e+00 3.300e+00 1.810e+01 1.700e+02 2.150e+02\n",
      "  3.230e+01 2.317e+03]\n",
      " [1.220e+01 1.280e+01 6.900e+00 4.000e+00 2.080e+01 9.900e+01 1.120e+02\n",
      "  6.650e+01 2.784e+03]]\n",
      "[[59.9]\n",
      " [55.5]\n",
      " [55.3]\n",
      " [55.8]\n",
      " [60.1]\n",
      " [58.5]\n",
      " [57.4]\n",
      " [58.5]\n",
      " [58.3]\n",
      " [58.2]\n",
      " [56.5]\n",
      " [59.2]\n",
      " [58.1]\n",
      " [58.8]\n",
      " [56.5]\n",
      " [57.1]\n",
      " [58.3]\n",
      " [59.4]\n",
      " [61.2]\n",
      " [60.4]\n",
      " [58.6]\n",
      " [57.5]\n",
      " [60.6]\n",
      " [65.9]\n",
      " [62.6]\n",
      " [63.9]\n",
      " [59.5]\n",
      " [59.4]\n",
      " [61. ]\n",
      " [59.4]\n",
      " [60.2]\n",
      " [57.5]\n",
      " [68.9]\n",
      " [59. ]\n",
      " [56.9]\n",
      " [57.7]\n",
      " [58. ]\n",
      " [55.1]\n",
      " [58.3]\n",
      " [55.4]\n",
      " [59.1]\n",
      " [60.6]\n",
      " [58.2]\n",
      " [57.8]\n",
      " [57.2]\n",
      " [49.7]\n",
      " [56. ]\n",
      " [56. ]\n",
      " [54.7]\n",
      " [56.2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# получение данных из файлов\n",
    "X = np.genfromtxt(\"./datasets/lab1_X.csv\")\n",
    "y = np.genfromtxt(\"./datasets/lab1_y.csv\").reshape(50, 1)\n",
    "\n",
    "print(f\"Матрицы X и y:\\n{X}\\n{y}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877e664d",
   "metadata": {},
   "source": [
    "Разделим все данные на выборку для обучения и выборку для валидации (```X_train```, ```y_train``` и ```X_test```, ```y_test``` соответственно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4cb2e2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерности матриц: X_test - (15, 9), X_train - (35, 9), y_test - (15, 1), y_train - (35, 1)\n"
     ]
    }
   ],
   "source": [
    "# разделяем данные так: 70% для обучения, 30% для валидации\n",
    "split = round(X.shape[0] * 0.7)\n",
    "\n",
    "# Разделение для матрицы признаков\n",
    "X_train = X[:split]\n",
    "X_test = X[split:]\n",
    "\n",
    "# Разделение для матрицы целевых значений\n",
    "y_train = y[:split]\n",
    "y_test = y[split:]\n",
    "\n",
    "print(f\"Размерности матриц: X_test - {X_test.shape}, X_train - {X_train.shape}, y_test - {y_test.shape}, y_train - {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6c54c4",
   "metadata": {},
   "source": [
    "### 1. Нормирование (масштабирование) исходных данных.\n",
    "\n",
    "Теперь необходимо нормализовать данные, поскольку разброс значенией данных слишком большой. Будет использоваться Z-нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ee19f1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.41047775 -0.39437582 -0.4083067  -0.41391524 -0.39817515 -0.00883409\n",
      "  -0.11195881 -0.38695807  3.38342651]\n",
      " [-0.41011591 -0.39021464 -0.40975407 -0.41210603 -0.39727055 -0.15899816\n",
      "  -0.12100484 -0.3704943   4.07997068]\n",
      " [-0.40884946 -0.38750084 -0.41156327 -0.41463892 -0.38731992 -0.1083404\n",
      "  -0.16261657 -0.3818923   3.96960914]\n",
      " [-0.4092113  -0.38551071 -0.41065867 -0.41373432 -0.39220477 -0.19156386\n",
      "  -0.22232036 -0.34588911  4.08901671]\n",
      " [-0.4064975  -0.39437582 -0.40903038 -0.4135534  -0.39292845 -0.11738643\n",
      "  -0.15537975 -0.38207322  3.36533445]\n",
      " [-0.40939222 -0.39347121 -0.41102051 -0.41463892 -0.3950995  -0.16261657\n",
      "  -0.15176134 -0.37266535  2.77553341]\n",
      " [-0.40993499 -0.39003372 -0.41174419 -0.41427708 -0.38768176 -0.17347181\n",
      "  -0.18251784 -0.36217196  3.16270342]\n",
      " [-0.40884946 -0.39347121 -0.41083959 -0.41409616 -0.39130017 -0.06672867\n",
      "  -0.14271531 -0.37501732  2.50958018]\n",
      " [-0.40884946 -0.39238569 -0.41174419 -0.41518168 -0.38677715 -0.09386676\n",
      "  -0.13547849 -0.36796141  2.52767223]\n",
      " [-0.40866854 -0.39256661 -0.4083067  -0.41481984 -0.3950995   0.51764475\n",
      "  -0.06672867 -0.38858636  1.50547104]\n",
      " [-0.41011591 -0.39130017 -0.40848762 -0.41373432 -0.39401398 -0.16442578\n",
      "  -0.12462325 -0.36669497  1.7171481 ]\n",
      " [-0.4074021  -0.3941949  -0.40939222 -0.41518168 -0.3889482  -0.03597218\n",
      "  -0.13186008 -0.38207322  1.94329881]\n",
      " [-0.40903038 -0.39075741 -0.41011591 -0.4153626  -0.39473766 -0.13728769\n",
      "  -0.12824167 -0.37899757  2.24543615]\n",
      " [-0.40866854 -0.39256661 -0.41065867 -0.41463892 -0.39274753 -0.08843914\n",
      "  -0.15899816 -0.38731992  3.34181478]\n",
      " [-0.40957314 -0.3880436  -0.41102051 -0.41481984 -0.38822452 -0.14633372\n",
      "  -0.12462325 -0.37139891  3.39247253]\n",
      " [-0.40993499 -0.3880436  -0.40975407 -0.41409616 -0.38677715 -0.06130106\n",
      "  -0.1065312  -0.39383306  2.75563214]\n",
      " [-0.40939222 -0.39184293 -0.41029683 -0.4135534  -0.40143172 -0.09748517\n",
      "  -0.14452452 -0.38460611  3.39609095]\n",
      " [-0.40577381 -0.39962251 -0.41156327 -0.41680997 -0.39274753 -0.20603751\n",
      "  -0.21146513 -0.3449845   3.39790015]\n",
      " [-0.40685934 -0.39763239 -0.41047775 -0.41717181 -0.39564226 -0.18432704\n",
      "  -0.19518227 -0.36036275  2.82257275]\n",
      " [-0.40468829 -0.39962251 -0.41029683 -0.41735273 -0.39401398 -0.16080737\n",
      "  -0.2042283  -0.37375087  2.63079695]\n",
      " [-0.40848762 -0.39365214 -0.41192511 -0.41608629 -0.39220477 -0.17528101\n",
      "  -0.2042283  -0.36524761  2.78638864]\n",
      " [-0.40866854 -0.39148109 -0.41102051 -0.41590536 -0.39347121 -0.09567596\n",
      "  -0.09386676 -0.38333966  2.78457944]\n",
      " [-0.40378369 -0.39708963 -0.40866854 -0.41590536 -0.38931004 -0.18975466\n",
      "  -0.18794545 -0.33937597  2.00843021]\n",
      " [-0.3837015  -0.40957314 -0.41065867 -0.42079022 -0.39130017 -0.2675505\n",
      "  -0.28021494 -0.34806015  0.79445322]\n",
      " [-0.39835607 -0.40432645 -0.41029683 -0.41699089 -0.39690871 -0.19156386\n",
      "  -0.23860321 -0.34625095  1.13096547]\n",
      " [-0.39980343 -0.40450737 -0.41047775 -0.41717181 -0.39365214 -0.20060989\n",
      "  -0.22955718 -0.34046149  1.25037304]\n",
      " [-0.39907975 -0.39962251 -0.41120143 -0.41843825 -0.39093833 -0.19156386\n",
      "  -0.24041242 -0.34570819  1.32816888]\n",
      " [-0.40505013 -0.39546134 -0.40722118 -0.41409616 -0.38840544 -0.1065312\n",
      "  -0.13366928 -0.36452392  2.40826466]\n",
      " [-0.40378369 -0.39871791 -0.40848762 -0.41500076 -0.38388242 -0.14995213\n",
      "  -0.14452452 -0.35149764  1.9740553 ]\n",
      " [-0.4064975  -0.39455674 -0.40866854 -0.414458   -0.38931004 -0.15899816\n",
      "  -0.1698534  -0.36271472  2.28523868]\n",
      " [-0.40287908 -0.40016528 -0.40993499 -0.41644813 -0.39003372 -0.13728769\n",
      "  -0.07758391 -0.36452392  1.4928066 ]\n",
      " [-0.40613565 -0.39835607 -0.41102051 -0.41699089 -0.3898528  -0.13728769\n",
      "  -0.16261657 -0.37592192  3.04148664]\n",
      " [-0.40685934 -0.39672778 -0.40993499 -0.4153626  -0.38225414 -0.21870195\n",
      "  -0.18432704 -0.33195822  4.38934485]\n",
      " [-0.40450737 -0.39871791 -0.40957314 -0.41590536 -0.38750084 -0.21508354\n",
      "  -0.16080737 -0.33394835  2.35217928]\n",
      " [-0.4064975  -0.39455674 -0.41246787 -0.41626721 -0.3889482  -0.09024835\n",
      "  -0.1065312  -0.3766456   4.37848962]]\n"
     ]
    }
   ],
   "source": [
    "# функции для нахождения среднего и стандартного распределения\n",
    "X_train = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "X_test = (X_test - np.mean(X_test)) / np.std(X_test)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8666173",
   "metadata": {},
   "source": [
    "### 2. Расчет весов линейной регрессии по аналитической формуле.\n",
    "\n",
    "После нормализации можно рассчитать веса с помощью аналитической формулы (здесь также будут использоваться функции numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "415bcc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полученные веса:\n",
      "[[-105.34037223]\n",
      " [-458.9797658 ]\n",
      " [ 487.78769156]\n",
      " [-191.16376235]\n",
      " [ 110.10871375]\n",
      " [   2.60991367]\n",
      " [ -12.15662621]\n",
      " [  12.59801378]\n",
      " [   0.72561761]]\n"
     ]
    }
   ],
   "source": [
    "cov_mat = np.matmul(np.transpose(X_train), X_train) # получение ковариационной матрицы\n",
    "temp = np.matmul(np.linalg.inv(cov_mat), np.transpose(X_train)) # произведение обратной ковариационной матрицы и X транспонированной\n",
    "w = np.matmul(temp, y_train) # получение матрицы весов\n",
    "\n",
    "print(f\"Полученные веса:\\n{w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7b7f93",
   "metadata": {},
   "source": [
    "### 3. Построение и интепретация корреляционной матрицы. Определение степени мультиколлинеарности на основе числа обусловленности.\n",
    "\n",
    "Теперь определим степень мультиколлинеарности на основе числа обусловленности. Будет использоваться функция ```eigvals``` из linalg для подсчета собственных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b2db269e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ковариационная матрица:\n",
      "[[  5.77530015   5.61473232   5.83138838   5.90545595   5.56519485\n",
      "    1.76908459   2.2683329    5.20386329 -38.04295817]\n",
      " [  5.61473232   5.46181614   5.67085926   5.74335203   5.41197705\n",
      "    1.73367595   2.21566683   5.05750609 -36.80000384]\n",
      " [  5.83138838   5.67085926   5.8889558    5.96395566   5.62002904\n",
      "    1.79516637   2.29662149   5.25364292 -38.33037116]\n",
      " [  5.90545595   5.74335203   5.96395566   6.04001011   5.69162012\n",
      "    1.81849941   2.3269085    5.32016797 -38.77942472]\n",
      " [  5.56519485   5.41197705   5.62002904   5.69162012   5.36401479\n",
      "    1.70867317   2.19131117   5.01451046 -36.55880406]\n",
      " [  1.76908459   1.73367595   1.79516637   1.81849941   1.70867317\n",
      "    1.07744186   0.82449584   1.55892519 -11.97819387]\n",
      " [  2.2683329    2.21566683   2.29662149   2.3269085    2.19131117\n",
      "    0.82449584   0.97668671   2.02953017 -14.61923909]\n",
      " [  5.20386329   5.05750609   5.25364292   5.32016797   5.01451046\n",
      "    1.55892519   2.02953017   4.69693412 -34.31414729]\n",
      " [-38.04295817 -36.80000384 -38.33037116 -38.77942472 -36.55880406\n",
      "  -11.97819387 -14.61923909 -34.31414729 279.71884031]]\n",
      "Число обусловленности: 29227053.848741435\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ковариационная матрица:\\n{cov_mat}\")\n",
    "print(f\"Число обусловленности: {np.linalg.cond(cov_mat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa2ea57",
   "metadata": {},
   "source": [
    "### 4. Анализ регрессионных остатков.\n",
    "\n",
    "Найдем среднеквадратическую ошибку (MSE) для матрицы ```X_train```, будем искать регрессионные остатки относительно ```y_train```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fa14ff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.7560210016827977\n"
     ]
    }
   ],
   "source": [
    "# MSE для обучающий данных\n",
    "Eps_train = np.matmul(X_train, w) - y_train\n",
    "MSE_train = np.matmul(np.transpose(Eps_train), Eps_train) / X.shape[0]\n",
    "\n",
    "print(f\"MSE: {MSE_train[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad02b6ac",
   "metadata": {},
   "source": [
    "Теперь найдем MSE для валидационной выборки (```X_test``` и ```y_test```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bf63769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.078294172537214\n"
     ]
    }
   ],
   "source": [
    "# MSE для валидационных данных\n",
    "Eps_test = np.matmul(X_test, w) - y_test\n",
    "MSE_test = np.matmul(np.transpose(Eps_test), Eps_test) / X.shape[0]\n",
    "\n",
    "print(f\"MSE: {MSE_test[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf56f4",
   "metadata": {},
   "source": [
    "### 5. Определение весов линейной регрессии градиентным методом. Проанализировать изменение ошибки от итерации к итерации\n",
    "\n",
    "Сначала инициализурем весы (каждый параметр будет равен единице)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b6071b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Инициализация весов\n",
    "w = np.ones((X_train.shape[1], 1))\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451de50",
   "metadata": {},
   "source": [
    "Теперь циклично будем расчитывать оценочные значения по весам, градиент функции потерь и новые значения весов. Эти шаги будут выполняться пока не будет слишком маленького изменения среднеквадратичной ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "948692ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1: 3521.4684261866596\n",
      "Эпоха 2: 2263.06551740901\n",
      "Эпоха 3: 1497.864551371973\n",
      "Эпоха 4: 1030.754749796388\n",
      "Эпоха 5: 743.8813684161681\n",
      "Эпоха 6: 566.0527165048513\n",
      "Эпоха 7: 454.2619379635492\n",
      "Эпоха 8: 382.52612768092774\n",
      "Эпоха 9: 335.1451301998233\n",
      "Эпоха 10: 302.6298337716286\n",
      "Эпоха 11: 279.2428441590897\n",
      "Эпоха 12: 261.5130386807727\n",
      "Эпоха 13: 247.33834578696852\n",
      "Эпоха 14: 235.44381410815143\n",
      "Эпоха 15: 225.05427722083775\n",
      "Эпоха 16: 215.69663487127826\n",
      "Эпоха 17: 207.08042303997954\n",
      "Эпоха 18: 199.0256708750172\n",
      "Эпоха 19: 191.41931924374956\n",
      "Эпоха 20: 184.1888908119582\n",
      "Эпоха 21: 177.28658032767598\n",
      "Эпоха 22: 170.6796389703485\n",
      "Эпоха 23: 164.34456056131918\n",
      "Эпоха 24: 158.26356433148814\n",
      "Эпоха 25: 152.42246503138998\n",
      "Эпоха 26: 146.8093812081932\n",
      "Эпоха 27: 141.41394993871785\n",
      "Эпоха 28: 136.22684765682837\n",
      "Эпоха 29: 131.2394960490145\n",
      "Эпоха 30: 126.44387991099632\n",
      "Эпоха 31: 121.8324328016301\n",
      "Эпоха 32: 117.39796381253598\n",
      "Эпоха 33: 113.13360933136819\n",
      "Эпоха 34: 109.03280005484312\n",
      "Эпоха 35: 105.08923736031896\n",
      "Эпоха 36: 101.29687547196518\n",
      "Эпоха 37: 97.64990726344097\n",
      "Эпоха 38: 94.1427523883619\n",
      "Эпоха 39: 90.77004694305086\n",
      "Эпоха 40: 87.52663417624511\n",
      "Эпоха 41: 84.4075559479658\n",
      "Эпоха 42: 81.40804475320166\n",
      "Эпоха 43: 78.52351619475762\n",
      "Эпоха 44: 75.74956183127166\n",
      "Эпоха 45: 73.08194235172567\n",
      "Эпоха 46: 70.5165810432209\n",
      "Эпоха 47: 68.04955752826402\n",
      "Эпоха 48: 65.67710175367591\n",
      "Эпоха 49: 63.39558821691159\n",
      "Эпоха 50: 61.201530417933874\n",
      "Эпоха 51: 59.09157552632775\n",
      "Эпоха 52: 57.06249925439857\n",
      "Эпоха 53: 55.11120092774938\n",
      "Эпоха 54: 53.23469874539954\n",
      "Эпоха 55: 51.43012522195721\n",
      "Эпоха 56: 49.694722804730986\n",
      "Эпоха 57: 48.02583965899475\n",
      "Эпоха 58: 46.420925614909166\n",
      "Эпоха 59: 44.87752826987302\n",
      "Эпоха 60: 43.39328924032819\n",
      "Эпоха 61: 41.96594055727752\n",
      "Эпоха 62: 40.59330119999938\n",
      "Эпоха 63: 39.273273762657155\n",
      "Эпоха 64: 38.00384124870634\n",
      "Эпоха 65: 36.783063988198045\n",
      "Эпоха 66: 35.60907667326718\n",
      "Эпоха 67: 34.48008550727315\n",
      "Эпоха 68: 33.39436546323616\n",
      "Эпоха 69: 32.35025764737833\n",
      "Эпоха 70: 31.34616676374051\n",
      "Эпоха 71: 30.380558675999463\n",
      "Эпоха 72: 29.45195806275901\n",
      "Эпоха 73: 28.558946162731438\n",
      "Эпоха 74: 27.70015860636331\n",
      "Эпоха 75: 26.874283330591133\n",
      "Эпоха 76: 26.08005857354045\n",
      "Эпоха 77: 25.316270946102875\n",
      "Эпоха 78: 24.58175357744437\n",
      "Эпоха 79: 23.875384331610004\n",
      "Эпоха 80: 23.19608409249973\n",
      "Эпоха 81: 22.54281511459392\n",
      "Эпоха 82: 21.914579436907967\n",
      "Эпоха 83: 21.310417357752073\n",
      "Эпоха 84: 20.72940596796482\n",
      "Эпоха 85: 20.17065774037901\n",
      "Эпоха 86: 19.633319173363905\n",
      "Эпоха 87: 19.116569486370643\n",
      "Эпоха 88: 18.619619365487306\n",
      "Эпоха 89: 18.141709757086268\n",
      "Эпоха 90: 17.682110707719943\n",
      "Эпоха 91: 17.240120248492374\n",
      "Эпоха 92: 16.815063322201087\n",
      "Эпоха 93: 16.406290751609554\n",
      "Эпоха 94: 16.01317824727379\n",
      "Эпоха 95: 15.63512545340619\n",
      "Эпоха 96: 15.271555030318787\n",
      "Эпоха 97: 14.921911772043144\n",
      "Эпоха 98: 14.585661757778771\n",
      "Эпоха 99: 14.262291535872656\n",
      "Эпоха 100: 13.95130733908313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 0.1\n",
    "learning_rate = 0.1\n",
    "S = []\n",
    "\n",
    "for i in range(100):\n",
    "    # 2. Расчет предсказанного значения y_pred по весам w\n",
    "    y_pred = np.matmul(X_train, w)\n",
    "    Eps_train = y_train - y_pred\n",
    "\n",
    "    # 3. Расчет ошибки и градиента функции потерь\n",
    "    S.append((1 / X_train.shape[0]) * np.matmul(np.transpose(Eps_train), Eps_train)[0][0])\n",
    "\n",
    "    # 4. Установка новых значений весов\n",
    "    dS = (-2 / X_train.shape[0]) * np.transpose(np.matmul(np.transpose(Eps_train), X_train))\n",
    "    w -= learning_rate * dS\n",
    "\n",
    "[print(f\"Эпоха {_ + 1}: {S[_]}\") for _ in range(len(S))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1272f971",
   "metadata": {},
   "source": [
    "После использования градиентного спуска можно расчитать MSE для набора тестовых данных ```X_test``` и ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e5326a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18.08018066946566\n"
     ]
    }
   ],
   "source": [
    "Eps_test = y_test - np.matmul(X_test, w) # регресионный остатки\n",
    "MSE_test = (1 / X_test.shape[0]) * np.matmul(np.transpose(Eps_test), Eps_test) # среднеквадратичная ошибка\n",
    "\n",
    "print(f\"MSE: {MSE_test[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee37b45",
   "metadata": {},
   "source": [
    "### 6. Сравнение результатов по аналитическому и градиентному методу.\n",
    "\n",
    "Если сравнивать ошибки на тестовых данных по аналитическому и градиентному методу, то можно увидеть, что результаты для первого метода лучше, чем для первого."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c6c84",
   "metadata": {},
   "source": [
    "### 7. С помощью библиотеки sklearn сделать fit-predict модели линейной регрессии. Сравнить результаты с ранее полученными.\n",
    "\n",
    "Теперь создадим модель через scikit-learn. Для этого воспользуемся одноименной библиотеки и функцией ```LinearRegression```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d9d74284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 27.512899496009197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# инициализация модели\n",
    "model = LinearRegression()\n",
    "\n",
    "# обучение модели\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# получение оценочных значений\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# регрессионные остатки и MSE\n",
    "Eps_test = y_test - y_pred\n",
    "MSE_test = (1 / X_test.shape[0]) * np.matmul(np.transpose(Eps_test), Eps_test)\n",
    "\n",
    "print(f\"MSE: {MSE_test[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8f384",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
